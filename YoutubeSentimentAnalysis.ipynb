{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YoutubeSentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s23nqCM-w-r"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCXGKQIi-yV4",
        "outputId": "c228a0c1-2044-4365-9069-2f79f6df3b2d"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from textblob import Word\r\n",
        "import re\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.linear_model import SGDClassifier\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFppWEuD-1Ia"
      },
      "source": [
        "data = pd.read_csv('text_emotion.csv')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDraOdwf_S44"
      },
      "source": [
        "# Preprocessing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umjJDsR0_UoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74256449-6dcb-4596-d8a4-af591fef632e"
      },
      "source": [
        "# Drop the author Column as it's not useful\r\n",
        "data = data.drop(\"author\", axis=1)\r\n",
        "\r\n",
        "# Dropping rows with other emotion labels\r\n",
        "data = data.drop(data[data.sentiment == 'anger'].index)\r\n",
        "data = data.drop(data[data.sentiment == 'boredom'].index)\r\n",
        "data = data.drop(data[data.sentiment == 'enthusiasm'].index)\r\n",
        "data = data.drop(data[data.sentiment == 'empty'].index)\r\n",
        "data = data.drop(data[data.sentiment == 'fun'].index)\r\n",
        "data = data.drop(data[data.sentiment == 'relief'].index)\r\n",
        "data = data.drop(data[data.sentiment == 'surprise'].index)\r\n",
        "data = data.drop(data[data.sentiment == 'love'].index)\r\n",
        "data = data.drop(data[data.sentiment == 'hate'].index)\r\n",
        "data = data.drop(data[data.sentiment == 'neutral'].index)\r\n",
        "data = data.drop(data[data.sentiment == 'worry'].index)\r\n",
        "\r\n",
        "# Making all letters lowercase\r\n",
        "data['content'] = data['content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\r\n",
        "\r\n",
        "# Removing Punctuation, Symbols\r\n",
        "data['content'] = data['content'].str.replace('[^\\w\\s]',' ')\r\n",
        "\r\n",
        "# Removing Stop Words using NLTK\r\n",
        "stop = stopwords.words('english')\r\n",
        "data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\r\n",
        "\r\n",
        "# Lemmatisation\r\n",
        "data['content'] = data['content'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\r\n",
        "\r\n",
        "#Correcting Letter Repetitions\r\n",
        "def de_repeat(text):\r\n",
        "    pattern = re.compile(r\"(.)\\1{2,}\")\r\n",
        "    return pattern.sub(r\"\\1\\1\", text)\r\n",
        "\r\n",
        "data['content'] = data['content'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))\r\n",
        "\r\n",
        "# Code to find the top 10,000 rarest words appearing in the data\r\n",
        "freq = pd.Series(' '.join(data['content']).split()).value_counts()[-10000:]\r\n",
        "\r\n",
        "# Removing all those rarely appearing words from the data\r\n",
        "freq = list(freq.index)\r\n",
        "data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\r\n",
        "\r\n",
        "# Encoding output labels 'sadness' as '1' & 'happiness' as '0'\r\n",
        "lbl_enc = preprocessing.LabelEncoder()\r\n",
        "y = lbl_enc.fit_transform(data.sentiment.values)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<input>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "<ipython-input-16-fa1e3e3e3526>:21: DeprecationWarning: invalid escape sequence \\w\n",
            "  data['content'] = data['content'].str.replace('[^\\w\\s]',' ')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U655bTPYALUp"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAeCELA3ANF-"
      },
      "source": [
        "# Splitting into training and testing data in 90:10 ratio\r\n",
        "X_train, X_val, y_train, y_val = train_test_split(data.content.values, y, stratify=y, random_state=42, test_size=0.1, shuffle=True)\r\n",
        "\r\n",
        "# Extracting Count Vectors Parameters\r\n",
        "count_vect = CountVectorizer(analyzer='word')\r\n",
        "count_vect.fit(data['content'])\r\n",
        "X_train_count =  count_vect.transform(X_train)\r\n",
        "X_val_count =  count_vect.transform(X_val)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4LwJJwLAcpz"
      },
      "source": [
        "# Modeling & Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0NMXoW1Ael-"
      },
      "source": [
        "# Model : Linear SVM\r\n",
        "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\r\n",
        "\r\n",
        "# Train\r\n",
        "lsvm.fit(X_train_count, y_train)\r\n",
        "\r\n",
        "# Prediction\r\n",
        "y_pred = lsvm.predict(X_val_count)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43IhoJ_EETAN",
        "outputId": "434a9f28-7482-4589-9c16-0e85ff8bce1a"
      },
      "source": [
        "# Find the Accuracy of the Training Model\r\n",
        "Temp = accuracy_score(y_pred, y_val)\r\n",
        "Accuracy = str(Temp)\r\n",
        "print('LSVM with Count Vectors accuracy result : ' + Accuracy)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSVM with Count Vectors accuracy result : 0.7842003853564548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhLnVny4BEfw"
      },
      "source": [
        "# Take Youtube Subtitle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItF9FwBlBDNi",
        "outputId": "bbcdf452-0ed6-4288-bf82-8f140ea29973"
      },
      "source": [
        "!pip install pytube\r\n",
        "from pytube import YouTube\r\n",
        "import requests\r\n",
        "import re"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.6/dist-packages (10.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from pytube) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn1-H-t7BLAu"
      },
      "source": [
        "def urlify(s):\r\n",
        "  s = re.sub(r\"[^\\w\\s]\", '', s)\r\n",
        "  s = re.sub(r\"\\s+\", '-', s)\r\n",
        "  return s\r\n",
        "\r\n",
        "vids = r'https://www.youtube.com/watch?v=mx3krJHlUzc'\r\n",
        "source = YouTube(vids)\r\n",
        "\r\n",
        "spaces = 0\r\n",
        "source = YouTube(vids)\r\n",
        "en_caption = source.captions.get_by_language_code('a.en')\r\n",
        "en_caption_convert_to_srt = en_caption.generate_srt_captions()\r\n",
        "\r\n",
        "filename = source.title\r\n",
        "filename = urlify(filename)\r\n",
        "filename = filename + \".txt\"\r\n",
        "\r\n",
        "# save the caption to a file named Output.txt\r\n",
        "text_file = open(filename, \"w\")\r\n",
        "text_file.write(en_caption_convert_to_srt)\r\n",
        "text_file.close()\r\n",
        "\r\n",
        "file = open(filename, \"r\")\r\n",
        "lines = file.readlines()\r\n",
        "file.close()\r\n",
        "\r\n",
        "text = ''\r\n",
        "for line in lines:\r\n",
        "    if re.search('^[0-9]+$', line) is None and re.search('^[0-9]{2}:[0-9]{2}:[0-9]{2}', line) is None and re.search('^$', line) is None and re.search('^\\[.*]$', line) is None:\r\n",
        "        spaces = 0\r\n",
        "        text += ' ' + line.rstrip('\\n')\r\n",
        "\r\n",
        "    text = text.lstrip()\r\n",
        "    spaces = spaces + 1\r\n",
        "    if re.search('^\\[.*]$', line):\r\n",
        "        spaces = 0\r\n",
        "    if spaces == 4:\r\n",
        "        text = text + ';'\r\n",
        "text_file = open(filename, \"w\")\r\n",
        "text_file.write(text)\r\n",
        "text_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIEwTG5QCd1-"
      },
      "source": [
        "# Read the text file and seperate each sentence with \";\" symbol \r\n",
        "# Untuk bagian ini kami belum membuat pengambilan data secara langsung melainkan menginput nama filenya karena masih dalam bentuk prototype\r\n",
        "subtitle = pd.read_csv('2021-Tech-Im-Ready-For.txt', sep = \";\", header = None)\r\n",
        "\r\n",
        "# Transpose the matrix from column to row and row to column\r\n",
        "subtitle = subtitle.T"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzeaRxOHCm-O"
      },
      "source": [
        "# Preprocessing Youtube Subtitle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNdH29iSCo8G"
      },
      "source": [
        "# Drop all \"NULL\" data from the dataset\r\n",
        "subtitles = subtitle.dropna()\r\n",
        "\r\n",
        "# Doing some preprocessing on the subtitles\r\n",
        "subtitles[0] = subtitles[0].str.replace('[^\\w\\s]',' ')\r\n",
        "stop = stopwords.words('english')\r\n",
        "subtitles[0] = subtitles[0].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\r\n",
        "subtitles[0] = subtitles[0].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\r\n",
        "\r\n",
        "# Extracting Count Vectors feature from the subtitles\r\n",
        "subtitle_count = count_vect.transform(subtitles[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njMB2gsoDQ1r"
      },
      "source": [
        "# Predicting the emotion of the subtitle using trained linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE6VvhOADVqO",
        "outputId": "bc263fe5-a698-4617-e8ff-6492185e4b18"
      },
      "source": [
        "# Predicting the emotion of the subtitle using trained linear SVM\r\n",
        "subtitle_pred = lsvm.predict(subtitle_count)\r\n",
        "print(subtitle_pred)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 0 1\n",
            " 0 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 1 0\n",
            " 1 0 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0\n",
            " 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 1 1 1 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0\n",
            " 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1\n",
            " 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0\n",
            " 0 1 1 1 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0\n",
            " 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0\n",
            " 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 1 1 1 0 1\n",
            " 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0\n",
            " 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0\n",
            " 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1\n",
            " 0 0 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 1\n",
            " 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phMOz_W_DbJU",
        "outputId": "3cdd4d1a-a967-49a6-d603-df140f4f2bce"
      },
      "source": [
        "# Count all the happiness and sadness number from \"subtitle_pred\"\r\n",
        "happinessCount = np.count_nonzero(subtitle_pred == 0)\r\n",
        "sadnessCount = np.count_nonzero(subtitle_pred == 1)\r\n",
        "\r\n",
        "# Get the percentage for both happiness and sadness\r\n",
        "happinessPercent = happinessCount / (happinessCount + sadnessCount) * 100\r\n",
        "sadnessPercent = sadnessCount / (happinessCount + sadnessCount) * 100\r\n",
        "\r\n",
        "# Make the percentage into a string for printing\r\n",
        "hpPercentage = str(happinessPercent)\r\n",
        "sdPercentage = str(sadnessPercent)\r\n",
        "\r\n",
        "# Print both happiness and sadness results\r\n",
        "print(\"Happiness Percent = \" + hpPercentage + \"%\")\r\n",
        "print(\"Sadness Percent = \" + sdPercentage + \"%\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Happiness Percent = 48.263254113345525%\n",
            "Sadness Percent = 51.736745886654475%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "qKZ7em0kM5uu",
        "outputId": "34aab8dc-e764-49c2-8feb-3f6e49892cff"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "names = ['happy', 'sad']\r\n",
        "values = [happinessCount, sadnessCount]\r\n",
        "\r\n",
        "plt.figure(figsize=(9, 3))\r\n",
        "\r\n",
        "plt.subplot(131)\r\n",
        "plt.bar(names, values)\r\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALwAAADCCAYAAADzYagaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAKV0lEQVR4nO3df4xcVRnG8e9DRUSpllKs8iMukhrTaix1bUhEAxIEqqYQBUtUWkIsmtZA4j9gohBDEwgiCYliWmlaQMVGIBBpkNpgUBPoL0vZgqUVitCUtqAgBgXbvv5xz8Kw2W1nZ3b2Tvd9Pslk7px778yZybNnz947+15FBGZZHFZ3B8xGkwNvqTjwlooDb6k48JaKA2+pvKPuDgBMmjQpenp66u6GjRHr169/MSKOHWxdVwS+p6eHdevW1d0NGyMkPTvUOk9pLBUH3lJx4C0VB95SceAtla44SmMjo+fK++vuwqjZft0XWtrPI7yl4sBbKg68peLAWyoOvKXiwFsqDryl4sBbKg68peLAWypd/9WCTKfLofVT5tYcj/CWigNvqTjwlspBAy/pREkPSXpC0mZJl5f2ayTtkLSx3GY17HOVpG2Stkg6u5NvwGw4mvmjdS/w3YjYIGk8sF7SqrLupoj4UePGkqYCc4BpwHHA7yV9JCL2jWTHzVpx0BE+InZGxIay/CrwJHD8AXaZDdwZEa9HxDPANmDmSHTWrF3DmsNL6gFOAR4tTQslbZK0VNLRpe144LmG3Z7nwD8gZqOm6cBLOgq4C7giIv4F3AKcDEwHdgI3DueFJc2XtE7Suj179gxnV7OWNRV4SYdThf0XEXE3QETsioh9EbEfWMJb05YdwIkNu59Q2t4mIhZHRG9E9B577KBV0cxGXDNHaQTcCjwZET9uaP9gw2bnA31l+T5gjqQjJJ0ETAHWjFyXzVrXzFGaTwPfAB6XtLG0fQ+4SNJ0IIDtwGUAEbFZ0grgCaojPAt8hMa6xUEDHxF/AjTIqpUH2GcRsKiNfpl1hM+0WioOvKXiwFsqDryl4sBbKg68peLAWyoOvKXiwFsqDryl4sBbKg68peLAWyoOvKXiwFsqDryl4sBbKg68peLAWyrt1JacKGmVpK3l/ujSLkk3l9qSmyTN6PSbMGtWMyN8f23JqcCpwIJSP/JKYHVETAFWl8cA51KV5pgCzKcq2GTWFdqpLTkbWF42Ww6cV5ZnA7dF5RFgwoAaNma1aae25OSI2FlWvQBMLstN1ZZ0qT2rQzu1Jd8UEUFVkKlpLrVndWi5tiSwq3+qUu53l/amakua1aHl2pJUNSTnluW5wL0N7ReXozWnAq80TH3MatVObcnrgBWSLgWeBS4s61YCs6guhPAacMmI9tisDe3UlgQ4c5DtA1jQZr/MOsJnWi0VB95SceAtFQfeUnHgLRUH3lJx4C0VB95SceAtFQfeUnHgLRUH3lJx4C0VB95SceAtFQfeUnHgLRUH3lJp5p+4l0raLamvoe0aSTskbSy3WQ3rripl9rZIOrtTHTdrRTMj/DLgnEHab4qI6eW2EqCU4JsDTCv7/FTSuJHqrFm7mim19zDwjyafbzZwZ0S8HhHPUFUumNlG/8xGVDtz+IWlOvDS/srBNFlmD1xqz+rRauBvAU4GpgM7gRuH+wQutWd1aCnwEbErIvZFxH5gCW9NW1xmz7paS4EfUP76fKD/CM59wBxJR0g6iapG/Jr2umg2cg5aeUzSr4DTgUmSngeuBk6XNJ2qYvB24DKAiNgsaQXwBNWFFBZExL7OdN1s+JoptXfRIM23HmD7RcCidjpl1ik+02qpOPCWigNvqTjwlooDb6k48JaKA2+pOPCWigNvqTjwlooDb6k48JaKA2+pOPCWigNvqTjwlooDb6k48JZKq6X2JkpaJWlruT+6tEvSzaXU3iZJMzrZebPharXU3pXA6oiYAqwujwHOpapUMAWYT1W/xqxrtFpqbzawvCwvB85raL8tKo8AEwaU9DCrVatz+MkRsbMsvwBMLstNl9ozq0Pbf7RGRFDVpxkW15a0OrQa+F39U5Vyv7u0N11qz7UlrQ6tBv4+YG5Zngvc29B+cTlacyrwSsPUx6x2rZbauw5YIelS4FngwrL5SmAWVV3414BLOtBns5a1WmoP4MxBtg1gQbudMusUn2m1VBx4S8WBt1QceEvFgbdUHHhLxYG3VBx4S8WBt1QceEvFgbdUHHhLxYG3VBx4S8WBt1QceEvFgbdUHHhLxYG3VA76P60HImk78CqwD9gbEb2SJgK/BnqA7cCFEfHP9rppNjJGYoQ/IyKmR0RveTxU3Umz2nViSjNU3Umz2rUb+AAelLRe0vzSNlTdybdxqT2rQ1tzeOC0iNgh6f3AKkl/bVwZESFp0LqTEbEYWAzQ29s77NqUZq1oa4SPiB3lfjdwDzCToetOmtWu5cBLeo+k8f3LwOeBPoauO2lWu3amNJOBeyT1P88vI+IBSWsZvO6kWe1aDnxEPA18YpD2lxik7qRZN/CZVkvFgbdUHHhLxYG3VBx4S8WBt1QceEvFgbdUHHhLxYG3VBx4S8WBt1QceEvFgbdUHHhLxYG3VBx4S8WBt1Q6FnhJ50jaImmbJFcfs67QkcBLGgf8BDgXmApcJGlqJ17LbDg6NcLPBLZFxNMR8QZwJ1UJPrNadSrwxwPPNTx+vrSZ1ardUnstK7Uo++tR/lvSlrr6MoRJwIuj/aK6frRfsW3d+Dl9aKgVnQr8DuDEhscnlLY3NdaW7EaS1jWUALchHGqfU6emNGuBKZJOkvROYA5VCT6zWnVkhI+IvZIWAr8DxgFLI2JzJ17LbDg6NoePiJXAyk49/yjo2ulWlzmkPidFuDS75eGvFlgqYzrwknok9dXdj4y69bMf04E3GyhD4MdJWiJps6QHJR0p6ZuS1kp6TNJdkt4NIGmZpJ+Vi609JemLpX2epHsl/UHSVklXl/YfSrqi/4UkLZJ0eT1vszPKlV7uL59Vn6SvSvpB+fz6JC1WuSqGpE+W7R4DFtTc9cFFxJi9UV0ceS8wvTxeAXwdOKZhm2uB75TlZcADVAPBFKqvRLwLmAfsBI4BjqS6tE9vef4NZd/DgL81PvdYuAFfBpY0PH4fMLHh8e3Al8ryJuCzZfkGoK/u/g+8ZRjhn4mIjWV5PVVIPybpj5IeB74GTGvYfkVE7I+IrcDTwEdL+6qIeCki/gPcTXUFw+3AS5JOobrG1V+iugLKWPI4cJak6yV9JiJeAc6Q9Gj5/D4HTJM0AZgQEQ+X/W6vq8MHUtt3aUbR6w3L+6hG6GXAeRHxmKR5wOkN2ww8ThsHaf851W+ADwBL2+5tl4mIpyTNAGYB10paTTVd6Y2I5yRdQ/Vb8JCQYYQfzHhgp6TDqUb4RhdIOkzSycCHgf4vtZ0laaKkI6muLv7n0n4PcA7wKaozy2OKpOOA1yLiDqppyoyy6kVJRwFfAYiIl4GXJZ1W1g/8XLtChhF+MN8HHgX2lPvxDev+DqwB3gt8KyL+W/4mWwPcRfVFuDsiYh1ARLwh6SHg5YjYN3pvYdR8HLhB0n7gf8C3qX7g+6iutL62YdtLgKXlYtQPjnZHm+EzrQ0kLQN+GxG/GdA+j+pX+MJB9jkM2ABcUOb91sWyTmlGRPm3xW3Aaof90OAR3lLxCG+pOPCWigNvqTjwlooDb6k48JbK/wEW+dnWPZA04gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 648x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}